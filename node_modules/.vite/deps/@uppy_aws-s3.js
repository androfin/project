import {
  AbortController as AbortController2,
  BasePlugin,
  ErrorWithCause_default,
  EventManager,
  RateLimitedQueue,
  UserFacingApiError_default,
  createAbortError,
  fetchWithNetworkError,
  filterFilesToEmitUploadStarted,
  filterNonFailedFiles,
  getAllowedMetaFields,
  getSocketHost
} from "./chunk-YEYOVYRJ.js";
import {
  __commonJS,
  __export,
  __privateAdd,
  __privateGet,
  __privateMethod,
  __privateSet,
  __publicField,
  __toESM
} from "./chunk-WOOG5QLI.js";

// node_modules/retry/lib/retry_operation.js
var require_retry_operation = __commonJS({
  "node_modules/retry/lib/retry_operation.js"(exports, module) {
    function RetryOperation(timeouts, options) {
      if (typeof options === "boolean") {
        options = { forever: options };
      }
      this._originalTimeouts = JSON.parse(JSON.stringify(timeouts));
      this._timeouts = timeouts;
      this._options = options || {};
      this._maxRetryTime = options && options.maxRetryTime || Infinity;
      this._fn = null;
      this._errors = [];
      this._attempts = 1;
      this._operationTimeout = null;
      this._operationTimeoutCb = null;
      this._timeout = null;
      this._operationStart = null;
      this._timer = null;
      if (this._options.forever) {
        this._cachedTimeouts = this._timeouts.slice(0);
      }
    }
    module.exports = RetryOperation;
    RetryOperation.prototype.reset = function() {
      this._attempts = 1;
      this._timeouts = this._originalTimeouts.slice(0);
    };
    RetryOperation.prototype.stop = function() {
      if (this._timeout) {
        clearTimeout(this._timeout);
      }
      if (this._timer) {
        clearTimeout(this._timer);
      }
      this._timeouts = [];
      this._cachedTimeouts = null;
    };
    RetryOperation.prototype.retry = function(err) {
      if (this._timeout) {
        clearTimeout(this._timeout);
      }
      if (!err) {
        return false;
      }
      var currentTime = (/* @__PURE__ */ new Date()).getTime();
      if (err && currentTime - this._operationStart >= this._maxRetryTime) {
        this._errors.push(err);
        this._errors.unshift(new Error("RetryOperation timeout occurred"));
        return false;
      }
      this._errors.push(err);
      var timeout = this._timeouts.shift();
      if (timeout === void 0) {
        if (this._cachedTimeouts) {
          this._errors.splice(0, this._errors.length - 1);
          timeout = this._cachedTimeouts.slice(-1);
        } else {
          return false;
        }
      }
      var self = this;
      this._timer = setTimeout(function() {
        self._attempts++;
        if (self._operationTimeoutCb) {
          self._timeout = setTimeout(function() {
            self._operationTimeoutCb(self._attempts);
          }, self._operationTimeout);
          if (self._options.unref) {
            self._timeout.unref();
          }
        }
        self._fn(self._attempts);
      }, timeout);
      if (this._options.unref) {
        this._timer.unref();
      }
      return true;
    };
    RetryOperation.prototype.attempt = function(fn, timeoutOps) {
      this._fn = fn;
      if (timeoutOps) {
        if (timeoutOps.timeout) {
          this._operationTimeout = timeoutOps.timeout;
        }
        if (timeoutOps.cb) {
          this._operationTimeoutCb = timeoutOps.cb;
        }
      }
      var self = this;
      if (this._operationTimeoutCb) {
        this._timeout = setTimeout(function() {
          self._operationTimeoutCb();
        }, self._operationTimeout);
      }
      this._operationStart = (/* @__PURE__ */ new Date()).getTime();
      this._fn(this._attempts);
    };
    RetryOperation.prototype.try = function(fn) {
      console.log("Using RetryOperation.try() is deprecated");
      this.attempt(fn);
    };
    RetryOperation.prototype.start = function(fn) {
      console.log("Using RetryOperation.start() is deprecated");
      this.attempt(fn);
    };
    RetryOperation.prototype.start = RetryOperation.prototype.try;
    RetryOperation.prototype.errors = function() {
      return this._errors;
    };
    RetryOperation.prototype.attempts = function() {
      return this._attempts;
    };
    RetryOperation.prototype.mainError = function() {
      if (this._errors.length === 0) {
        return null;
      }
      var counts = {};
      var mainError = null;
      var mainErrorCount = 0;
      for (var i = 0; i < this._errors.length; i++) {
        var error = this._errors[i];
        var message = error.message;
        var count = (counts[message] || 0) + 1;
        counts[message] = count;
        if (count >= mainErrorCount) {
          mainError = error;
          mainErrorCount = count;
        }
      }
      return mainError;
    };
  }
});

// node_modules/retry/lib/retry.js
var require_retry = __commonJS({
  "node_modules/retry/lib/retry.js"(exports) {
    var RetryOperation = require_retry_operation();
    exports.operation = function(options) {
      var timeouts = exports.timeouts(options);
      return new RetryOperation(timeouts, {
        forever: options && (options.forever || options.retries === Infinity),
        unref: options && options.unref,
        maxRetryTime: options && options.maxRetryTime
      });
    };
    exports.timeouts = function(options) {
      if (options instanceof Array) {
        return [].concat(options);
      }
      var opts = {
        retries: 10,
        factor: 2,
        minTimeout: 1 * 1e3,
        maxTimeout: Infinity,
        randomize: false
      };
      for (var key in options) {
        opts[key] = options[key];
      }
      if (opts.minTimeout > opts.maxTimeout) {
        throw new Error("minTimeout is greater than maxTimeout");
      }
      var timeouts = [];
      for (var i = 0; i < opts.retries; i++) {
        timeouts.push(this.createTimeout(i, opts));
      }
      if (options && options.forever && !timeouts.length) {
        timeouts.push(this.createTimeout(i, opts));
      }
      timeouts.sort(function(a, b) {
        return a - b;
      });
      return timeouts;
    };
    exports.createTimeout = function(attempt, opts) {
      var random = opts.randomize ? Math.random() + 1 : 1;
      var timeout = Math.round(random * Math.max(opts.minTimeout, 1) * Math.pow(opts.factor, attempt));
      timeout = Math.min(timeout, opts.maxTimeout);
      return timeout;
    };
    exports.wrap = function(obj, options, methods) {
      if (options instanceof Array) {
        methods = options;
        options = null;
      }
      if (!methods) {
        methods = [];
        for (var key in obj) {
          if (typeof obj[key] === "function") {
            methods.push(key);
          }
        }
      }
      for (var i = 0; i < methods.length; i++) {
        var method = methods[i];
        var original = obj[method];
        obj[method] = (function retryWrapper(original2) {
          var op = exports.operation(options);
          var args = Array.prototype.slice.call(arguments, 1);
          var callback = args.pop();
          args.push(function(err) {
            if (op.retry(err)) {
              return;
            }
            if (err) {
              arguments[0] = op.mainError();
            }
            callback.apply(this, arguments);
          });
          op.attempt(function() {
            original2.apply(obj, args);
          });
        }).bind(obj, original);
        obj[method].options = options;
      }
    };
  }
});

// node_modules/retry/index.js
var require_retry2 = __commonJS({
  "node_modules/retry/index.js"(exports, module) {
    module.exports = require_retry();
  }
});

// node_modules/p-retry/index.js
var import_retry = __toESM(require_retry2());

// node_modules/is-network-error/index.js
var objectToString = Object.prototype.toString;
var isError = (value) => objectToString.call(value) === "[object Error]";
var errorMessages = /* @__PURE__ */ new Set([
  "network error",
  // Chrome
  "Failed to fetch",
  // Chrome
  "NetworkError when attempting to fetch resource.",
  // Firefox
  "The Internet connection appears to be offline.",
  // Safari 16
  "Network request failed",
  // `cross-fetch`
  "fetch failed",
  // Undici (Node.js)
  "terminated",
  // Undici (Node.js)
  " A network error occurred.",
  // Bun (WebKit)
  "Network connection lost"
  // Cloudflare Workers (fetch)
]);
function isNetworkError(error) {
  const isValid = error && isError(error) && error.name === "TypeError" && typeof error.message === "string";
  if (!isValid) {
    return false;
  }
  const { message, stack } = error;
  if (message === "Load failed") {
    return stack === void 0 || "__sentry_captured__" in error;
  }
  if (message.startsWith("error sending request for url")) {
    return true;
  }
  return errorMessages.has(message);
}

// node_modules/p-retry/index.js
var AbortError = class extends Error {
  constructor(message) {
    super();
    if (message instanceof Error) {
      this.originalError = message;
      ({ message } = message);
    } else {
      this.originalError = new Error(message);
      this.originalError.stack = this.stack;
    }
    this.name = "AbortError";
    this.message = message;
  }
};
var decorateErrorWithCounts = (error, attemptNumber, options) => {
  const retriesLeft = options.retries - (attemptNumber - 1);
  error.attemptNumber = attemptNumber;
  error.retriesLeft = retriesLeft;
  return error;
};
async function pRetry(input, options) {
  return new Promise((resolve, reject) => {
    options = { ...options };
    options.onFailedAttempt ?? (options.onFailedAttempt = () => {
    });
    options.shouldRetry ?? (options.shouldRetry = () => true);
    options.retries ?? (options.retries = 10);
    const operation = import_retry.default.operation(options);
    const abortHandler = () => {
      var _a;
      operation.stop();
      reject((_a = options.signal) == null ? void 0 : _a.reason);
    };
    if (options.signal && !options.signal.aborted) {
      options.signal.addEventListener("abort", abortHandler, { once: true });
    }
    const cleanUp = () => {
      var _a;
      (_a = options.signal) == null ? void 0 : _a.removeEventListener("abort", abortHandler);
      operation.stop();
    };
    operation.attempt(async (attemptNumber) => {
      try {
        const result = await input(attemptNumber);
        cleanUp();
        resolve(result);
      } catch (error) {
        try {
          if (!(error instanceof Error)) {
            throw new TypeError(`Non-error was thrown: "${error}". You should only throw errors.`);
          }
          if (error instanceof AbortError) {
            throw error.originalError;
          }
          if (error instanceof TypeError && !isNetworkError(error)) {
            throw error;
          }
          decorateErrorWithCounts(error, attemptNumber, options);
          if (!await options.shouldRetry(error)) {
            operation.stop();
            reject(error);
          }
          await options.onFailedAttempt(error);
          if (!operation.retry(error)) {
            throw operation.mainError();
          }
        } catch (finalError) {
          decorateErrorWithCounts(finalError, attemptNumber, options);
          cleanUp();
          reject(finalError);
        }
      }
    });
  });
}

// node_modules/@uppy/companion-client/package.json
var package_default = {
  name: "@uppy/companion-client",
  description: "Client library for communication with Companion. Intended for use in Uppy plugins.",
  version: "5.1.1",
  license: "MIT",
  type: "module",
  sideEffects: false,
  scripts: {
    build: "tsc --build tsconfig.build.json",
    typecheck: "tsc --build",
    test: "vitest run --environment=jsdom --silent='passed-only'"
  },
  keywords: [
    "file uploader",
    "uppy",
    "uppy-plugin",
    "companion",
    "provider"
  ],
  homepage: "https://uppy.io",
  bugs: {
    url: "https://github.com/transloadit/uppy/issues"
  },
  repository: {
    type: "git",
    url: "git+https://github.com/transloadit/uppy.git"
  },
  files: [
    "src",
    "lib",
    "dist",
    "CHANGELOG.md"
  ],
  exports: {
    ".": "./lib/index.js",
    "./package.json": "./package.json"
  },
  dependencies: {
    "@uppy/utils": "^7.1.1",
    "namespace-emitter": "^2.0.1",
    "p-retry": "^6.1.0"
  },
  devDependencies: {
    jsdom: "^26.1.0",
    typescript: "^5.8.3",
    vitest: "^3.2.4"
  },
  peerDependencies: {
    "@uppy/core": "^5.1.1"
  }
};

// node_modules/@uppy/companion-client/lib/AuthError.js
var AuthError = class extends Error {
  constructor() {
    super("Authorization required");
    __publicField(this, "isAuthError");
    this.name = "AuthError";
    this.isAuthError = true;
  }
};
var AuthError_default = AuthError;

// node_modules/@uppy/companion-client/lib/RequestClient.js
function stripSlash(url) {
  return url.replace(/\/$/, "");
}
var retryCount = 10;
var socketActivityTimeoutMs = 5 * 60 * 1e3;
var authErrorStatusCode = 401;
var HttpError = class extends Error {
  constructor({ statusCode, message }) {
    super(message);
    __publicField(this, "statusCode");
    this.name = "HttpError";
    this.statusCode = statusCode;
  }
};
async function handleJSONResponse(res) {
  if (res.status === authErrorStatusCode) {
    throw new AuthError_default();
  }
  if (res.ok) {
    return res.json();
  }
  let errMsg = `Failed request with status: ${res.status}. ${res.statusText}`;
  let errData;
  try {
    errData = await res.json();
    if (errData.message)
      errMsg = `${errMsg} message: ${errData.message}`;
    if (errData.requestId)
      errMsg = `${errMsg} request-Id: ${errData.requestId}`;
  } catch (cause) {
    throw new Error(errMsg, { cause });
  }
  if (res.status >= 400 && res.status <= 499 && errData.message) {
    throw new UserFacingApiError_default(errData.message);
  }
  throw new HttpError({ statusCode: res.status, message: errMsg });
}
function emitSocketProgress(uploader, progressData, file) {
  const { progress, bytesUploaded, bytesTotal } = progressData;
  if (progress) {
    uploader.uppy.log(`Upload progress: ${progress}`);
    uploader.uppy.emit("upload-progress", file, {
      uploadStarted: file.progress.uploadStarted ?? 0,
      bytesUploaded,
      bytesTotal
    });
  }
}
var _companionHeaders, _RequestClient_instances, getUrl_fn, _requestSocketToken, awaitRemoteFileUpload_fn;
var RequestClient = class {
  constructor(uppy, opts) {
    __privateAdd(this, _RequestClient_instances);
    __privateAdd(this, _companionHeaders);
    __publicField(this, "uppy");
    __publicField(this, "opts");
    __privateAdd(this, _requestSocketToken, async ({ file, postBody, signal }) => {
      var _a;
      if (((_a = file.remote) == null ? void 0 : _a.url) == null) {
        throw new Error("Cannot connect to an undefined URL");
      }
      const res = await this.post(file.remote.url, {
        ...file.remote.body,
        ...postBody
      }, { signal });
      return res.token;
    });
    this.uppy = uppy;
    this.opts = opts;
    this.onReceiveResponse = this.onReceiveResponse.bind(this);
    __privateSet(this, _companionHeaders, opts.companionHeaders);
  }
  setCompanionHeaders(headers) {
    __privateSet(this, _companionHeaders, headers);
  }
  [Symbol.for("uppy test: getCompanionHeaders")]() {
    return __privateGet(this, _companionHeaders);
  }
  get hostname() {
    const { companion } = this.uppy.getState();
    const host = this.opts.companionUrl;
    return stripSlash((companion == null ? void 0 : companion[host]) ? companion[host] : host);
  }
  async headers(emptyBody = false) {
    const defaultHeaders = {
      Accept: "application/json",
      ...emptyBody ? void 0 : {
        // Passing those headers on requests with no data forces browsers to first make a preflight request.
        "Content-Type": "application/json"
      }
    };
    return {
      ...defaultHeaders,
      ...__privateGet(this, _companionHeaders)
    };
  }
  onReceiveResponse(res) {
    const { headers } = res;
    const state = this.uppy.getState();
    const companion = state.companion || {};
    const host = this.opts.companionUrl;
    if (headers.has("i-am") && headers.get("i-am") !== companion[host]) {
      this.uppy.setState({
        companion: { ...companion, [host]: headers.get("i-am") }
      });
    }
  }
  async request({ path, method = "GET", data, skipPostResponse, signal }) {
    try {
      const headers = await this.headers(!data);
      const response = await fetchWithNetworkError(__privateMethod(this, _RequestClient_instances, getUrl_fn).call(this, path), {
        method,
        signal,
        headers,
        credentials: this.opts.companionCookiesRule || "same-origin",
        body: data ? JSON.stringify(data) : null
      });
      if (!skipPostResponse)
        this.onReceiveResponse(response);
      return await handleJSONResponse(response);
    } catch (err) {
      if (err.isAuthError || err.name === "UserFacingApiError" || err.name === "AbortError")
        throw err;
      throw new ErrorWithCause_default(`Could not ${method} ${__privateMethod(this, _RequestClient_instances, getUrl_fn).call(this, path)}`, {
        cause: err
      });
    }
  }
  async get(path, options) {
    return this.request({ ...options, path });
  }
  async post(path, data, options) {
    return this.request({ ...options, path, method: "POST", data });
  }
  async delete(path, data, options) {
    return this.request({ ...options, path, method: "DELETE", data });
  }
  /**
   * Remote uploading consists of two steps:
   * 1. #requestSocketToken which starts the download/upload in companion and returns a unique token for the upload.
   * Then companion will halt the upload until:
   * 2. #awaitRemoteFileUpload is called, which will open/ensure a websocket connection towards companion, with the
   * previously generated token provided. It returns a promise that will resolve/reject once the file has finished
   * uploading or is otherwise done (failed, canceled)
   */
  async uploadRemoteFile(file, reqBody, options) {
    try {
      const { signal, getQueue } = options || {};
      return await pRetry(async () => {
        var _a;
        const existingServerToken = (_a = this.uppy.getFile(file.id)) == null ? void 0 : _a.serverToken;
        if (existingServerToken != null) {
          this.uppy.log(`Connecting to exiting websocket ${existingServerToken}`);
          return __privateMethod(this, _RequestClient_instances, awaitRemoteFileUpload_fn).call(this, {
            file,
            queue: getQueue(),
            signal
          });
        }
        const queueRequestSocketToken = getQueue().wrapPromiseFunction(async (...args) => {
          try {
            return await __privateGet(this, _requestSocketToken).call(this, ...args);
          } catch (outerErr) {
            if (outerErr.isAuthError)
              throw new AbortError(outerErr);
            if (outerErr.cause == null)
              throw outerErr;
            const err = outerErr.cause;
            const isRetryableHttpError = () => [408, 409, 429, 418, 423].includes(err.statusCode) || err.statusCode >= 500 && err.statusCode <= 599 && ![501, 505].includes(err.statusCode);
            if (err.name === "HttpError" && !isRetryableHttpError())
              throw new AbortError(err);
            throw err;
          }
        }, { priority: -1 });
        const serverToken = await queueRequestSocketToken({
          file,
          postBody: reqBody,
          signal
        }).abortOn(signal);
        if (!this.uppy.getFile(file.id))
          return void 0;
        this.uppy.setFileState(file.id, { serverToken });
        return __privateMethod(this, _RequestClient_instances, awaitRemoteFileUpload_fn).call(this, {
          file: this.uppy.getFile(file.id),
          // re-fetching file because it might have changed in the meantime
          queue: getQueue(),
          signal
        });
      }, {
        retries: retryCount,
        signal,
        onFailedAttempt: (err) => this.uppy.log(`Retrying upload due to: ${err.message}`, "warning")
      });
    } catch (err) {
      if (err.name === "AbortError") {
        return void 0;
      }
      this.uppy.emit("upload-error", file, err);
      throw err;
    }
  }
};
_companionHeaders = new WeakMap();
_RequestClient_instances = new WeakSet();
getUrl_fn = function(url) {
  if (/^(https?:|)\/\//.test(url)) {
    return url;
  }
  return `${this.hostname}/${url}`;
};
_requestSocketToken = new WeakMap();
awaitRemoteFileUpload_fn = async function({ file, queue, signal }) {
  let removeEventHandlers;
  const { capabilities } = this.uppy.getState();
  try {
    return await new Promise((resolve, reject) => {
      const token = file.serverToken;
      const host = getSocketHost(file.remote.companionUrl);
      let socket;
      let socketAbortController;
      let activityTimeout;
      let { isPaused } = file;
      const socketSend = (action, payload) => {
        if (socket == null || socket.readyState !== socket.OPEN) {
          this.uppy.log(`Cannot send "${action}" to socket ${file.id} because the socket state was ${String(socket == null ? void 0 : socket.readyState)}`, "warning");
          return;
        }
        socket.send(JSON.stringify({
          action,
          payload: payload ?? {}
        }));
      };
      function sendState() {
        if (!capabilities.resumableUploads)
          return;
        if (isPaused)
          socketSend("pause");
        else
          socketSend("resume");
      }
      const createWebsocket = async () => {
        if (socketAbortController)
          socketAbortController.abort();
        socketAbortController = new AbortController();
        const onFatalError = (err) => {
          var _a;
          this.uppy.setFileState(file.id, { serverToken: null });
          (_a = socketAbortController == null ? void 0 : socketAbortController.abort) == null ? void 0 : _a.call(socketAbortController);
          reject(err);
        };
        function resetActivityTimeout() {
          clearTimeout(activityTimeout);
          if (isPaused)
            return;
          activityTimeout = setTimeout(() => onFatalError(new Error("Timeout waiting for message from Companion socket")), socketActivityTimeoutMs);
        }
        try {
          await queue.wrapPromiseFunction(async () => {
            const reconnectWebsocket = async () => new Promise((_, rejectSocket) => {
              socket = new WebSocket(`${host}/api/${token}`);
              resetActivityTimeout();
              socket.addEventListener("close", () => {
                socket = void 0;
                rejectSocket(new Error("Socket closed unexpectedly"));
              });
              socket.addEventListener("error", (error) => {
                this.uppy.log(`Companion socket error ${JSON.stringify(error)}, closing socket`, "warning");
                socket == null ? void 0 : socket.close();
              });
              socket.addEventListener("open", () => {
                sendState();
              });
              socket.addEventListener("message", (e) => {
                var _a, _b, _c;
                resetActivityTimeout();
                try {
                  const { action, payload } = JSON.parse(e.data);
                  switch (action) {
                    case "progress": {
                      emitSocketProgress(this, payload, this.uppy.getFile(file.id));
                      break;
                    }
                    case "success": {
                      const text = (_a = payload.response) == null ? void 0 : _a.responseText;
                      this.uppy.emit("upload-success", this.uppy.getFile(file.id), {
                        uploadURL: payload.url,
                        status: ((_b = payload.response) == null ? void 0 : _b.status) ?? 200,
                        body: text ? JSON.parse(text) : void 0
                      });
                      (_c = socketAbortController == null ? void 0 : socketAbortController.abort) == null ? void 0 : _c.call(socketAbortController);
                      resolve();
                      break;
                    }
                    case "error": {
                      const { message } = payload.error;
                      throw Object.assign(new Error(message), {
                        cause: payload.error
                      });
                    }
                    default:
                      this.uppy.log(`Companion socket unknown action ${action}`, "warning");
                  }
                } catch (err) {
                  onFatalError(err);
                }
              });
              const closeSocket = () => {
                this.uppy.log(`Closing socket ${file.id}`);
                clearTimeout(activityTimeout);
                if (socket)
                  socket.close();
                socket = void 0;
              };
              socketAbortController.signal.addEventListener("abort", () => {
                closeSocket();
              });
            });
            await pRetry(reconnectWebsocket, {
              retries: retryCount,
              signal: socketAbortController.signal,
              onFailedAttempt: () => {
                if (socketAbortController.signal.aborted)
                  return;
                this.uppy.log(`Retrying websocket ${file.id}`);
              }
            });
          })().abortOn(socketAbortController.signal);
        } catch (err) {
          if (socketAbortController.signal.aborted)
            return;
          onFatalError(err);
        }
      };
      const pause = (newPausedState) => {
        if (!capabilities.resumableUploads)
          return;
        isPaused = newPausedState;
        if (socket)
          sendState();
      };
      const onFileRemove = (targetFile) => {
        var _a;
        if (!capabilities.individualCancellation)
          return;
        if (targetFile.id !== file.id)
          return;
        socketSend("cancel");
        (_a = socketAbortController == null ? void 0 : socketAbortController.abort) == null ? void 0 : _a.call(socketAbortController);
        this.uppy.log(`upload ${file.id} was removed`);
        resolve();
      };
      const onCancelAll = () => {
        var _a;
        socketSend("cancel");
        (_a = socketAbortController == null ? void 0 : socketAbortController.abort) == null ? void 0 : _a.call(socketAbortController);
        this.uppy.log(`upload ${file.id} was canceled`);
        resolve();
      };
      const onFilePausedChange = (targetFile, newPausedState) => {
        if ((targetFile == null ? void 0 : targetFile.id) !== file.id)
          return;
        pause(newPausedState);
      };
      const onPauseAll = () => pause(true);
      const onResumeAll = () => pause(false);
      this.uppy.on("file-removed", onFileRemove);
      this.uppy.on("cancel-all", onCancelAll);
      this.uppy.on("upload-pause", onFilePausedChange);
      this.uppy.on("pause-all", onPauseAll);
      this.uppy.on("resume-all", onResumeAll);
      removeEventHandlers = () => {
        this.uppy.off("file-removed", onFileRemove);
        this.uppy.off("cancel-all", onCancelAll);
        this.uppy.off("upload-pause", onFilePausedChange);
        this.uppy.off("pause-all", onPauseAll);
        this.uppy.off("resume-all", onResumeAll);
      };
      signal.addEventListener("abort", () => {
        socketAbortController == null ? void 0 : socketAbortController.abort();
      });
      createWebsocket();
    });
  } finally {
    removeEventHandlers == null ? void 0 : removeEventHandlers();
  }
};
__publicField(RequestClient, "VERSION", package_default.version);

// node_modules/@uppy/companion-client/lib/tokenStorage.js
var tokenStorage_exports = {};
__export(tokenStorage_exports, {
  getItem: () => getItem,
  removeItem: () => removeItem,
  setItem: () => setItem
});
async function setItem(key, value) {
  localStorage.setItem(key, value);
}
async function getItem(key) {
  return localStorage.getItem(key);
}
async function removeItem(key) {
  localStorage.removeItem(key);
}

// node_modules/@uppy/aws-s3/package.json
var package_default2 = {
  name: "@uppy/aws-s3",
  description: "Upload to Amazon S3 with Uppy",
  version: "5.0.2",
  license: "MIT",
  type: "module",
  sideEffects: false,
  scripts: {
    build: "tsc --build tsconfig.build.json",
    typecheck: "tsc --build",
    test: "vitest run --environment=jsdom --silent='passed-only'"
  },
  keywords: [
    "file uploader",
    "aws s3",
    "amazon s3",
    "s3",
    "uppy",
    "uppy-plugin",
    "multipart"
  ],
  homepage: "https://uppy.io",
  bugs: {
    url: "https://github.com/transloadit/uppy/issues"
  },
  repository: {
    type: "git",
    url: "git+https://github.com/transloadit/uppy.git"
  },
  files: [
    "src",
    "lib",
    "dist",
    "CHANGELOG.md"
  ],
  exports: {
    ".": "./lib/index.js",
    "./package.json": "./package.json"
  },
  dependencies: {
    "@uppy/companion-client": "^5.1.1",
    "@uppy/utils": "^7.1.1"
  },
  devDependencies: {
    "@aws-sdk/client-s3": "^3.362.0",
    "@aws-sdk/s3-request-presigner": "^3.362.0",
    "@uppy/core": "^5.1.1",
    jsdom: "^26.1.0",
    nock: "^13.1.0",
    typescript: "^5.8.3",
    vitest: "^3.2.4",
    "whatwg-fetch": "3.6.2"
  },
  peerDependencies: {
    "@uppy/core": "^5.1.1"
  }
};

// node_modules/@uppy/aws-s3/lib/createSignedURL.js
function createCanonicalRequest({ method = "PUT", CanonicalUri = "/", CanonicalQueryString = "", SignedHeaders, HashedPayload }) {
  const headerKeys = Object.keys(SignedHeaders).map((k) => k.toLowerCase()).sort();
  return [
    method,
    CanonicalUri,
    CanonicalQueryString,
    ...headerKeys.map((k) => `${k}:${SignedHeaders[k]}`),
    "",
    headerKeys.join(";"),
    HashedPayload
  ].join("\n");
}
var ec = new TextEncoder();
var algorithm = { name: "HMAC", hash: "SHA-256" };
async function digest(data) {
  const { subtle } = globalThis.crypto;
  return subtle.digest(algorithm.hash, ec.encode(data));
}
async function generateHmacKey(secret) {
  const { subtle } = globalThis.crypto;
  return subtle.importKey("raw", typeof secret === "string" ? ec.encode(secret) : secret, algorithm, false, ["sign"]);
}
function arrayBufferToHexString(arrayBuffer) {
  const byteArray = new Uint8Array(arrayBuffer);
  let hexString = "";
  for (let i = 0; i < byteArray.length; i++) {
    hexString += byteArray[i].toString(16).padStart(2, "0");
  }
  return hexString;
}
async function hash(key, data) {
  const { subtle } = globalThis.crypto;
  return subtle.sign(algorithm, await generateHmacKey(key), ec.encode(data));
}
async function createSignedURL({ accountKey, accountSecret, sessionToken, bucketName, Key, Region, expires, uploadId, partNumber }) {
  const Service = "s3";
  const host = `${Service}.${Region}.amazonaws.com`;
  const CanonicalUri = `/${bucketName}/${encodeURI(Key).replace(/[;?:@&=+$,#!'()*]/g, (c) => `%${c.charCodeAt(0).toString(16).toUpperCase()}`)}`;
  const payload = "UNSIGNED-PAYLOAD";
  const requestDateTime = (/* @__PURE__ */ new Date()).toISOString().replace(/[-:]|\.\d+/g, "");
  const date = requestDateTime.slice(0, 8);
  const scope = `${date}/${Region}/${Service}/aws4_request`;
  const url = new URL(`https://${host}${CanonicalUri}`);
  url.searchParams.set("X-Amz-Algorithm", "AWS4-HMAC-SHA256");
  url.searchParams.set("X-Amz-Content-Sha256", payload);
  url.searchParams.set("X-Amz-Credential", `${accountKey}/${scope}`);
  url.searchParams.set("X-Amz-Date", requestDateTime);
  url.searchParams.set("X-Amz-Expires", expires);
  url.searchParams.set("X-Amz-Security-Token", sessionToken);
  url.searchParams.set("X-Amz-SignedHeaders", "host");
  if (partNumber)
    url.searchParams.set("partNumber", partNumber);
  if (uploadId)
    url.searchParams.set("uploadId", uploadId);
  url.searchParams.set("x-id", partNumber && uploadId ? "UploadPart" : "PutObject");
  const canonical = createCanonicalRequest({
    CanonicalUri,
    CanonicalQueryString: url.search.slice(1),
    SignedHeaders: {
      host
    },
    HashedPayload: payload
  });
  const hashedCanonical = arrayBufferToHexString(await digest(canonical));
  const stringToSign = [
    `AWS4-HMAC-SHA256`,
    // The algorithm used to create the hash of the canonical request.
    requestDateTime,
    // The date and time used in the credential scope.
    scope,
    // The credential scope. This restricts the resulting signature to the specified Region and service.
    hashedCanonical
    // The hash of the canonical request.
  ].join("\n");
  const kDate = await hash(`AWS4${accountSecret}`, date);
  const kRegion = await hash(kDate, Region);
  const kService = await hash(kRegion, Service);
  const kSigning = await hash(kService, "aws4_request");
  const signature = arrayBufferToHexString(await hash(kSigning, stringToSign));
  url.searchParams.set("X-Amz-Signature", signature);
  return url;
}

// node_modules/@uppy/aws-s3/lib/MultipartUploader.js
var MB = 1024 * 1024;
var defaultOptions = {
  getChunkSize(file) {
    return Math.ceil(file.size / 1e4);
  },
  onProgress() {
  },
  onPartComplete() {
  },
  onSuccess() {
  },
  onError(err) {
    throw err;
  }
};
function ensureInt(value) {
  if (typeof value === "string") {
    return parseInt(value, 10);
  }
  if (typeof value === "number") {
    return value;
  }
  throw new TypeError("Expected a number");
}
var pausingUploadReason = Symbol("pausing upload, not an actual error");
var _abortController, _chunks, _chunkState, _data, _file, _uploadHasStarted, _onError, _onSuccess, _shouldUseMultipart, _isRestoring, _onReject, _maxMultipartParts, _minPartSize, _MultipartUploader_instances, initChunks_fn, createUpload_fn, resumeUpload_fn, _onPartProgress, _onPartComplete, abortUpload_fn;
var MultipartUploader = class {
  constructor(data, options) {
    __privateAdd(this, _MultipartUploader_instances);
    __publicField(this, "options");
    __privateAdd(this, _abortController, new AbortController2());
    __privateAdd(this, _chunks, []);
    __privateAdd(this, _chunkState, []);
    /**
     * The (un-chunked) data to upload.
     */
    __privateAdd(this, _data);
    __privateAdd(this, _file);
    __privateAdd(this, _uploadHasStarted, false);
    __privateAdd(this, _onError);
    __privateAdd(this, _onSuccess);
    __privateAdd(this, _shouldUseMultipart);
    __privateAdd(this, _isRestoring);
    __privateAdd(this, _onReject, (err) => (err == null ? void 0 : err.cause) === pausingUploadReason ? null : __privateGet(this, _onError).call(this, err));
    __privateAdd(this, _maxMultipartParts, 1e4);
    __privateAdd(this, _minPartSize, 5 * MB);
    __privateAdd(this, _onPartProgress, (index) => (ev) => {
      if (!ev.lengthComputable)
        return;
      __privateGet(this, _chunkState)[index].uploaded = ensureInt(ev.loaded);
      const totalUploaded = __privateGet(this, _chunkState).reduce((n, c) => n + c.uploaded, 0);
      this.options.onProgress(totalUploaded, __privateGet(this, _data).size);
    });
    __privateAdd(this, _onPartComplete, (index) => (etag) => {
      __privateGet(this, _chunks)[index] = null;
      __privateGet(this, _chunkState)[index].etag = etag;
      __privateGet(this, _chunkState)[index].done = true;
      const part = {
        PartNumber: index + 1,
        ETag: etag
      };
      this.options.onPartComplete(part);
    });
    var _a;
    this.options = {
      ...defaultOptions,
      ...options
    };
    (_a = this.options).getChunkSize ?? (_a.getChunkSize = defaultOptions.getChunkSize);
    __privateSet(this, _data, data);
    __privateSet(this, _file, options.file);
    __privateSet(this, _onSuccess, this.options.onSuccess);
    __privateSet(this, _onError, this.options.onError);
    __privateSet(this, _shouldUseMultipart, this.options.shouldUseMultipart);
    __privateSet(this, _isRestoring, options.uploadId && options.key);
    __privateMethod(this, _MultipartUploader_instances, initChunks_fn).call(this);
  }
  start() {
    if (__privateGet(this, _uploadHasStarted)) {
      if (!__privateGet(this, _abortController).signal.aborted)
        __privateGet(this, _abortController).abort(pausingUploadReason);
      __privateSet(this, _abortController, new AbortController2());
      __privateMethod(this, _MultipartUploader_instances, resumeUpload_fn).call(this);
    } else if (__privateGet(this, _isRestoring)) {
      this.options.companionComm.restoreUploadFile(__privateGet(this, _file), {
        uploadId: this.options.uploadId,
        key: this.options.key
      });
      __privateMethod(this, _MultipartUploader_instances, resumeUpload_fn).call(this);
    } else {
      __privateMethod(this, _MultipartUploader_instances, createUpload_fn).call(this);
    }
  }
  pause() {
    __privateGet(this, _abortController).abort(pausingUploadReason);
    __privateSet(this, _abortController, new AbortController2());
  }
  abort(opts) {
    if (opts == null ? void 0 : opts.really)
      __privateMethod(this, _MultipartUploader_instances, abortUpload_fn).call(this);
    else
      this.pause();
  }
  [Symbol.for("uppy test: getChunkState")]() {
    return __privateGet(this, _chunkState);
  }
};
_abortController = new WeakMap();
_chunks = new WeakMap();
_chunkState = new WeakMap();
_data = new WeakMap();
_file = new WeakMap();
_uploadHasStarted = new WeakMap();
_onError = new WeakMap();
_onSuccess = new WeakMap();
_shouldUseMultipart = new WeakMap();
_isRestoring = new WeakMap();
_onReject = new WeakMap();
_maxMultipartParts = new WeakMap();
_minPartSize = new WeakMap();
_MultipartUploader_instances = new WeakSet();
// initChunks checks the user preference for using multipart uploads (opts.shouldUseMultipart)
// and calculates the optimal part size. When using multipart part uploads every part except for the last has
// to be at least 5 MB and there can be no more than 10K parts.
// This means we sometimes need to change the preferred part size from the user in order to meet these requirements.
initChunks_fn = function() {
  const fileSize = __privateGet(this, _data).size;
  const shouldUseMultipart = typeof __privateGet(this, _shouldUseMultipart) === "function" ? __privateGet(this, _shouldUseMultipart).call(this, __privateGet(this, _file)) : Boolean(__privateGet(this, _shouldUseMultipart));
  if (shouldUseMultipart && fileSize > __privateGet(this, _minPartSize)) {
    let chunkSize = Math.max(
      this.options.getChunkSize(__privateGet(this, _data)),
      // Math.max can take undefined but TS does not think so
      __privateGet(this, _minPartSize)
    );
    let arraySize = Math.floor(fileSize / chunkSize);
    if (arraySize > __privateGet(this, _maxMultipartParts)) {
      arraySize = __privateGet(this, _maxMultipartParts);
      chunkSize = fileSize / __privateGet(this, _maxMultipartParts);
    }
    __privateSet(this, _chunks, Array(arraySize));
    for (let offset = 0, j = 0; offset < fileSize; offset += chunkSize, j++) {
      const end = Math.min(fileSize, offset + chunkSize);
      const getData = () => {
        const i2 = offset;
        return __privateGet(this, _data).slice(i2, end);
      };
      __privateGet(this, _chunks)[j] = {
        getData,
        onProgress: __privateGet(this, _onPartProgress).call(this, j),
        onComplete: __privateGet(this, _onPartComplete).call(this, j),
        shouldUseMultipart
      };
      if (__privateGet(this, _isRestoring)) {
        const size = offset + chunkSize > fileSize ? fileSize - offset : chunkSize;
        __privateGet(this, _chunks)[j].setAsUploaded = () => {
          __privateGet(this, _chunks)[j] = null;
          __privateGet(this, _chunkState)[j].uploaded = size;
        };
      }
    }
  } else {
    __privateSet(this, _chunks, [
      {
        getData: () => __privateGet(this, _data),
        onProgress: __privateGet(this, _onPartProgress).call(this, 0),
        onComplete: __privateGet(this, _onPartComplete).call(this, 0),
        shouldUseMultipart
      }
    ]);
  }
  __privateSet(this, _chunkState, __privateGet(this, _chunks).map(() => ({ uploaded: 0 })));
};
createUpload_fn = function() {
  this.options.companionComm.uploadFile(__privateGet(this, _file), __privateGet(this, _chunks), __privateGet(this, _abortController).signal).then(__privateGet(this, _onSuccess), __privateGet(this, _onReject));
  __privateSet(this, _uploadHasStarted, true);
};
resumeUpload_fn = function() {
  this.options.companionComm.resumeUploadFile(__privateGet(this, _file), __privateGet(this, _chunks), __privateGet(this, _abortController).signal).then(__privateGet(this, _onSuccess), __privateGet(this, _onReject));
};
_onPartProgress = new WeakMap();
_onPartComplete = new WeakMap();
abortUpload_fn = function() {
  __privateGet(this, _abortController).abort();
  this.options.companionComm.abortFileUpload(__privateGet(this, _file)).catch((err) => this.options.log(err));
};
var MultipartUploader_default = MultipartUploader;

// node_modules/@uppy/aws-s3/lib/utils.js
function throwIfAborted(signal) {
  if (signal == null ? void 0 : signal.aborted) {
    throw createAbortError("The operation was aborted", {
      cause: signal.reason
    });
  }
}

// node_modules/@uppy/aws-s3/lib/HTTPCommunicationQueue.js
function removeMetadataFromURL(urlString) {
  const urlObject = new URL(urlString);
  urlObject.search = "";
  urlObject.hash = "";
  return urlObject.href;
}
var _abortMultipartUpload, _cache, _createMultipartUpload, _fetchSignature, _getUploadParameters, _listParts, _previousRetryDelay, _requests, _retryDelays, _sendCompletionRequest, _setS3MultipartState, _uploadPartBytes, _getFile, _HTTPCommunicationQueue_instances, shouldRetry_fn, nonMultipartUpload_fn;
var HTTPCommunicationQueue = class {
  constructor(requests, options, setS3MultipartState, getFile) {
    __privateAdd(this, _HTTPCommunicationQueue_instances);
    __privateAdd(this, _abortMultipartUpload);
    __privateAdd(this, _cache, /* @__PURE__ */ new WeakMap());
    __privateAdd(this, _createMultipartUpload);
    __privateAdd(this, _fetchSignature);
    __privateAdd(this, _getUploadParameters);
    __privateAdd(this, _listParts);
    __privateAdd(this, _previousRetryDelay);
    __privateAdd(this, _requests);
    __privateAdd(this, _retryDelays);
    __privateAdd(this, _sendCompletionRequest);
    __privateAdd(this, _setS3MultipartState);
    __privateAdd(this, _uploadPartBytes);
    __privateAdd(this, _getFile);
    __privateSet(this, _requests, requests);
    __privateSet(this, _setS3MultipartState, setS3MultipartState);
    __privateSet(this, _getFile, getFile);
    this.setOptions(options);
  }
  setOptions(options) {
    const requests = __privateGet(this, _requests);
    if ("abortMultipartUpload" in options) {
      __privateSet(this, _abortMultipartUpload, requests.wrapPromiseFunction(options.abortMultipartUpload, { priority: 1 }));
    }
    if ("createMultipartUpload" in options) {
      __privateSet(this, _createMultipartUpload, requests.wrapPromiseFunction(options.createMultipartUpload, { priority: -1 }));
    }
    if ("signPart" in options) {
      __privateSet(this, _fetchSignature, requests.wrapPromiseFunction(options.signPart));
    }
    if ("listParts" in options) {
      __privateSet(this, _listParts, requests.wrapPromiseFunction(options.listParts));
    }
    if ("completeMultipartUpload" in options) {
      __privateSet(this, _sendCompletionRequest, requests.wrapPromiseFunction(options.completeMultipartUpload, { priority: 1 }));
    }
    if ("retryDelays" in options) {
      __privateSet(this, _retryDelays, options.retryDelays ?? []);
    }
    if ("uploadPartBytes" in options) {
      __privateSet(this, _uploadPartBytes, requests.wrapPromiseFunction(options.uploadPartBytes, { priority: Infinity }));
    }
    if ("getUploadParameters" in options) {
      __privateSet(this, _getUploadParameters, requests.wrapPromiseFunction(options.getUploadParameters));
    }
  }
  async getUploadId(file, signal) {
    let cachedResult;
    for (; ; ) {
      if (file.data == null)
        throw new Error("File data is empty");
      cachedResult = __privateGet(this, _cache).get(file.data);
      if (cachedResult == null)
        break;
      try {
        return await cachedResult;
      } catch {
      }
    }
    const promise = __privateGet(this, _createMultipartUpload).call(this, __privateGet(this, _getFile).call(this, file), signal);
    const abortPromise = () => {
      if (file.data == null)
        throw new Error("File data is empty");
      promise.abort(signal.reason);
      __privateGet(this, _cache).delete(file.data);
    };
    signal.addEventListener("abort", abortPromise, { once: true });
    __privateGet(this, _cache).set(file.data, promise);
    promise.then(async (result) => {
      signal.removeEventListener("abort", abortPromise);
      __privateGet(this, _setS3MultipartState).call(this, file, result);
      if (file.data == null)
        throw new Error("File data is empty");
      __privateGet(this, _cache).set(file.data, result);
    }, () => {
      signal.removeEventListener("abort", abortPromise);
      if (file.data == null)
        throw new Error("File data is empty");
      __privateGet(this, _cache).delete(file.data);
    });
    return promise;
  }
  async abortFileUpload(file) {
    if (file.data == null)
      throw new Error("File data is empty");
    const result = __privateGet(this, _cache).get(file.data);
    if (result == null) {
      return;
    }
    __privateGet(this, _cache).delete(file.data);
    __privateGet(this, _setS3MultipartState).call(this, file, /* @__PURE__ */ Object.create(null));
    let awaitedResult;
    try {
      awaitedResult = await result;
    } catch {
      return;
    }
    await __privateGet(this, _abortMultipartUpload).call(this, __privateGet(this, _getFile).call(this, file), awaitedResult);
  }
  async uploadFile(file, chunks, signal) {
    throwIfAborted(signal);
    if (chunks.length === 1 && !chunks[0].shouldUseMultipart) {
      return __privateMethod(this, _HTTPCommunicationQueue_instances, nonMultipartUpload_fn).call(this, file, chunks[0], signal);
    }
    const { uploadId, key } = await this.getUploadId(file, signal);
    throwIfAborted(signal);
    try {
      const parts = await Promise.all(chunks.map((chunk, i) => this.uploadChunk(file, i + 1, chunk, signal)));
      throwIfAborted(signal);
      return await __privateGet(this, _sendCompletionRequest).call(this, __privateGet(this, _getFile).call(this, file), { key, uploadId, parts, signal }, signal).abortOn(signal);
    } catch (err) {
      if ((err == null ? void 0 : err.cause) !== pausingUploadReason && (err == null ? void 0 : err.name) !== "AbortError") {
        this.abortFileUpload(file);
      }
      throw err;
    }
  }
  restoreUploadFile(file, uploadIdAndKey) {
    if (file.data == null)
      throw new Error("File data is empty");
    __privateGet(this, _cache).set(file.data, uploadIdAndKey);
  }
  async resumeUploadFile(file, chunks, signal) {
    throwIfAborted(signal);
    if (chunks.length === 1 && chunks[0] != null && !chunks[0].shouldUseMultipart) {
      return __privateMethod(this, _HTTPCommunicationQueue_instances, nonMultipartUpload_fn).call(this, file, chunks[0], signal);
    }
    const { uploadId, key } = await this.getUploadId(file, signal);
    throwIfAborted(signal);
    const alreadyUploadedParts = await __privateGet(this, _listParts).call(this, __privateGet(this, _getFile).call(this, file), { uploadId, key, signal }, signal).abortOn(signal);
    throwIfAborted(signal);
    const parts = await Promise.all(chunks.map((chunk, i) => {
      var _a;
      const partNumber = i + 1;
      const alreadyUploadedInfo = alreadyUploadedParts.find(({ PartNumber }) => PartNumber === partNumber);
      if (alreadyUploadedInfo == null) {
        return this.uploadChunk(file, partNumber, chunk, signal);
      }
      (_a = chunk == null ? void 0 : chunk.setAsUploaded) == null ? void 0 : _a.call(chunk);
      return { PartNumber: partNumber, ETag: alreadyUploadedInfo.ETag };
    }));
    throwIfAborted(signal);
    return __privateGet(this, _sendCompletionRequest).call(this, __privateGet(this, _getFile).call(this, file), { key, uploadId, parts, signal }, signal).abortOn(signal);
  }
  async uploadChunk(file, partNumber, chunk, signal) {
    throwIfAborted(signal);
    const { uploadId, key } = await this.getUploadId(file, signal);
    const signatureRetryIterator = __privateGet(this, _retryDelays).values();
    const chunkRetryIterator = __privateGet(this, _retryDelays).values();
    const shouldRetrySignature = () => {
      const next = signatureRetryIterator.next();
      if (next == null || next.done) {
        return null;
      }
      return next.value;
    };
    for (; ; ) {
      throwIfAborted(signal);
      const chunkData = chunk.getData();
      const { onProgress, onComplete } = chunk;
      let signature;
      try {
        signature = await __privateGet(this, _fetchSignature).call(this, __privateGet(this, _getFile).call(this, file), {
          // Always defined for multipart uploads
          uploadId,
          key,
          partNumber,
          body: chunkData,
          signal
        }).abortOn(signal);
      } catch (err) {
        const timeout = shouldRetrySignature();
        if (timeout == null || signal.aborted) {
          throw err;
        }
        await new Promise((resolve) => setTimeout(resolve, timeout));
        continue;
      }
      throwIfAborted(signal);
      try {
        return {
          PartNumber: partNumber,
          ...await __privateGet(this, _uploadPartBytes).call(this, {
            signature,
            body: chunkData,
            size: chunkData.size,
            onProgress,
            onComplete,
            signal
          }).abortOn(signal)
        };
      } catch (err) {
        if (!await __privateMethod(this, _HTTPCommunicationQueue_instances, shouldRetry_fn).call(this, err, chunkRetryIterator))
          throw err;
      }
    }
  }
};
_abortMultipartUpload = new WeakMap();
_cache = new WeakMap();
_createMultipartUpload = new WeakMap();
_fetchSignature = new WeakMap();
_getUploadParameters = new WeakMap();
_listParts = new WeakMap();
_previousRetryDelay = new WeakMap();
_requests = new WeakMap();
_retryDelays = new WeakMap();
_sendCompletionRequest = new WeakMap();
_setS3MultipartState = new WeakMap();
_uploadPartBytes = new WeakMap();
_getFile = new WeakMap();
_HTTPCommunicationQueue_instances = new WeakSet();
shouldRetry_fn = async function(err, retryDelayIterator) {
  var _a;
  const requests = __privateGet(this, _requests);
  const status = (_a = err == null ? void 0 : err.source) == null ? void 0 : _a.status;
  if (status == null) {
    return false;
  }
  if (status === 403 && err.message === "Request has expired") {
    if (!requests.isPaused) {
      if (requests.limit === 1 || __privateGet(this, _previousRetryDelay) == null) {
        const next = retryDelayIterator.next();
        if (next == null || next.done) {
          return false;
        }
        __privateSet(this, _previousRetryDelay, next.value);
      }
      requests.rateLimit(0);
      await new Promise((resolve) => setTimeout(resolve, __privateGet(this, _previousRetryDelay)));
    }
  } else if (status === 429) {
    if (!requests.isPaused) {
      const next = retryDelayIterator.next();
      if (next == null || next.done) {
        return false;
      }
      requests.rateLimit(next.value);
    }
  } else if (status > 400 && status < 500 && status !== 409) {
    return false;
  } else if (typeof navigator !== "undefined" && navigator.onLine === false) {
    if (!requests.isPaused) {
      requests.pause();
      window.addEventListener("online", () => {
        requests.resume();
      }, { once: true });
    }
  } else {
    const next = retryDelayIterator.next();
    if (next == null || next.done) {
      return false;
    }
    await new Promise((resolve) => setTimeout(resolve, next.value));
  }
  return true;
};
nonMultipartUpload_fn = async function(file, chunk, signal) {
  const { method = "POST", url, fields, headers } = await __privateGet(this, _getUploadParameters).call(this, __privateGet(this, _getFile).call(this, file), {
    signal
  }).abortOn(signal);
  let body;
  const data = chunk.getData();
  if (method.toUpperCase() === "POST") {
    const formData = new FormData();
    Object.entries(fields).forEach(([key2, value]) => formData.set(key2, value));
    formData.set("file", data);
    body = formData;
  } else {
    body = data;
  }
  const { onProgress, onComplete } = chunk;
  const result = await __privateGet(this, _uploadPartBytes).call(this, {
    signature: { url, headers, method },
    body,
    size: data.size,
    onProgress,
    onComplete,
    signal
  }).abortOn(signal);
  const key = fields == null ? void 0 : fields.key;
  __privateGet(this, _setS3MultipartState).call(this, file, { key });
  return {
    ...result,
    location: result.location ?? removeMetadataFromURL(url),
    bucket: fields == null ? void 0 : fields.bucket,
    key
  };
};

// node_modules/@uppy/aws-s3/lib/index.js
function assertServerError(res) {
  if (res == null ? void 0 : res.error) {
    const error = new Error(res.message);
    Object.assign(error, res.error);
    throw error;
  }
  return res;
}
function getExpiry(credentials) {
  const expirationDate = credentials.Expiration;
  if (expirationDate) {
    const timeUntilExpiry = Math.floor((new Date(expirationDate) - Date.now()) / 1e3);
    if (timeUntilExpiry > 9) {
      return timeUntilExpiry;
    }
  }
  return void 0;
}
function getAllowedMetadata({ meta, allowedMetaFields, querify = false }) {
  const metaFields = allowedMetaFields ?? Object.keys(meta);
  if (!meta)
    return {};
  return Object.fromEntries(metaFields.filter((key) => meta[key] != null).map((key) => {
    const realKey = querify ? `metadata[${key}]` : key;
    const value = String(meta[key]);
    return [realKey, value];
  }));
}
var defaultOptions2 = {
  allowedMetaFields: true,
  limit: 6,
  getTemporarySecurityCredentials: false,
  shouldUseMultipart: (file) => (file.size || 0) > 100 * 1024 * 1024,
  retryDelays: [0, 1e3, 3e3, 5e3]
};
var _companionCommunicationQueue, _client, _AwsS3Multipart_instances, setClient_fn, assertHost_fn, _cachedTemporaryCredentials, getTemporarySecurityCredentials_fn, _setS3MultipartState2, _getFile2, uploadLocalFile_fn, getCompanionClientArgs_fn, _upload, _setCompanionHeaders, _setResumableUploadsCapability, _resetResumableCapability;
var _AwsS3Multipart = class _AwsS3Multipart extends BasePlugin {
  constructor(uppy, opts) {
    super(uppy, {
      ...defaultOptions2,
      uploadPartBytes: _AwsS3Multipart.uploadPartBytes,
      createMultipartUpload: null,
      listParts: null,
      abortMultipartUpload: null,
      completeMultipartUpload: null,
      signPart: null,
      getUploadParameters: null,
      ...opts
    });
    __privateAdd(this, _AwsS3Multipart_instances);
    __privateAdd(this, _companionCommunicationQueue);
    __privateAdd(this, _client);
    __publicField(this, "requests");
    __publicField(this, "uploaderEvents");
    __publicField(this, "uploaders");
    __privateAdd(this, _cachedTemporaryCredentials);
    __privateAdd(this, _setS3MultipartState2, (file, { key, uploadId }) => {
      const cFile = this.uppy.getFile(file.id);
      if (cFile == null) {
        return;
      }
      this.uppy.setFileState(file.id, {
        s3Multipart: {
          ...cFile.s3Multipart,
          key,
          uploadId
        }
      });
    });
    __privateAdd(this, _getFile2, (file) => {
      return this.uppy.getFile(file.id) || file;
    });
    __privateAdd(this, _upload, async (fileIDs) => {
      if (fileIDs.length === 0)
        return void 0;
      const files = this.uppy.getFilesByIds(fileIDs);
      const filesFiltered = filterNonFailedFiles(files);
      const filesToEmit = filterFilesToEmitUploadStarted(filesFiltered);
      this.uppy.emit("upload-start", filesToEmit);
      const promises = filesFiltered.map((file) => {
        if (file.isRemote) {
          const getQueue = () => this.requests;
          __privateGet(this, _setResumableUploadsCapability).call(this, false);
          const controller = new AbortController();
          const removedHandler = (removedFile) => {
            if (removedFile.id === file.id)
              controller.abort();
          };
          this.uppy.on("file-removed", removedHandler);
          const uploadPromise = this.uppy.getRequestClientForFile(file).uploadRemoteFile(file, __privateMethod(this, _AwsS3Multipart_instances, getCompanionClientArgs_fn).call(this, file), {
            signal: controller.signal,
            getQueue
          });
          this.requests.wrapSyncFunction(() => {
            this.uppy.off("file-removed", removedHandler);
          }, { priority: -1 })();
          return uploadPromise;
        }
        return __privateMethod(this, _AwsS3Multipart_instances, uploadLocalFile_fn).call(this, file);
      });
      const upload = await Promise.allSettled(promises);
      __privateGet(this, _setResumableUploadsCapability).call(this, true);
      return upload;
    });
    __privateAdd(this, _setCompanionHeaders, () => {
      var _a;
      (_a = __privateGet(this, _client)) == null ? void 0 : _a.setCompanionHeaders(this.opts.headers);
    });
    __privateAdd(this, _setResumableUploadsCapability, (boolean) => {
      const { capabilities } = this.uppy.getState();
      this.uppy.setState({
        capabilities: {
          ...capabilities,
          resumableUploads: boolean
        }
      });
    });
    __privateAdd(this, _resetResumableCapability, () => {
      __privateGet(this, _setResumableUploadsCapability).call(this, true);
    });
    this.type = "uploader";
    this.id = this.opts.id || "AwsS3Multipart";
    __privateMethod(this, _AwsS3Multipart_instances, setClient_fn).call(this, opts);
    const dynamicDefaultOptions = {
      createMultipartUpload: this.createMultipartUpload,
      listParts: this.listParts,
      abortMultipartUpload: this.abortMultipartUpload,
      completeMultipartUpload: this.completeMultipartUpload,
      signPart: (opts == null ? void 0 : opts.getTemporarySecurityCredentials) ? this.createSignedURL : this.signPart,
      getUploadParameters: (opts == null ? void 0 : opts.getTemporarySecurityCredentials) ? this.createSignedURL : this.getUploadParameters
    };
    for (const key of Object.keys(dynamicDefaultOptions)) {
      if (this.opts[key] == null) {
        this.opts[key] = dynamicDefaultOptions[key].bind(this);
      }
    }
    this.requests = this.opts.rateLimitedQueue ?? new RateLimitedQueue(this.opts.limit);
    __privateSet(this, _companionCommunicationQueue, new HTTPCommunicationQueue(this.requests, this.opts, __privateGet(this, _setS3MultipartState2), __privateGet(this, _getFile2)));
    this.uploaders = /* @__PURE__ */ Object.create(null);
    this.uploaderEvents = /* @__PURE__ */ Object.create(null);
  }
  [Symbol.for("uppy test: getClient")]() {
    return __privateGet(this, _client);
  }
  setOptions(newOptions) {
    __privateGet(this, _companionCommunicationQueue).setOptions(newOptions);
    super.setOptions(newOptions);
    __privateMethod(this, _AwsS3Multipart_instances, setClient_fn).call(this, newOptions);
  }
  /**
   * Clean up all references for a file's upload: the MultipartUploader instance,
   * any events related to the file, and the Companion WebSocket connection.
   *
   * Set `opts.abort` to tell S3 that the multipart upload is cancelled and must be removed.
   * This should be done when the user cancels the upload, not when the upload is completed or errored.
   */
  resetUploaderReferences(fileID, opts) {
    if (this.uploaders[fileID]) {
      this.uploaders[fileID].abort({ really: (opts == null ? void 0 : opts.abort) || false });
      this.uploaders[fileID] = null;
    }
    if (this.uploaderEvents[fileID]) {
      this.uploaderEvents[fileID].remove();
      this.uploaderEvents[fileID] = null;
    }
  }
  createMultipartUpload(file, signal) {
    __privateMethod(this, _AwsS3Multipart_instances, assertHost_fn).call(this, "createMultipartUpload");
    throwIfAborted(signal);
    const allowedMetaFields = getAllowedMetaFields(this.opts.allowedMetaFields, file.meta);
    const metadata = getAllowedMetadata({ meta: file.meta, allowedMetaFields });
    return __privateGet(this, _client).post("s3/multipart", {
      filename: file.name,
      type: file.type,
      metadata
    }, { signal }).then(assertServerError);
  }
  listParts(file, { key, uploadId, signal }, oldSignal) {
    signal ?? (signal = oldSignal);
    __privateMethod(this, _AwsS3Multipart_instances, assertHost_fn).call(this, "listParts");
    throwIfAborted(signal);
    const filename = encodeURIComponent(key);
    return __privateGet(this, _client).get(`s3/multipart/${encodeURIComponent(uploadId)}?key=${filename}`, { signal }).then(assertServerError);
  }
  completeMultipartUpload(file, { key, uploadId, parts, signal }, oldSignal) {
    signal ?? (signal = oldSignal);
    __privateMethod(this, _AwsS3Multipart_instances, assertHost_fn).call(this, "completeMultipartUpload");
    throwIfAborted(signal);
    const filename = encodeURIComponent(key);
    const uploadIdEnc = encodeURIComponent(uploadId);
    return __privateGet(this, _client).post(`s3/multipart/${uploadIdEnc}/complete?key=${filename}`, { parts: parts.map(({ ETag, PartNumber }) => ({ ETag, PartNumber })) }, { signal }).then(assertServerError);
  }
  async createSignedURL(file, options) {
    const data = await __privateMethod(this, _AwsS3Multipart_instances, getTemporarySecurityCredentials_fn).call(this, options);
    const expires = getExpiry(data.credentials) || 604800;
    const { uploadId, key, partNumber } = options;
    return {
      method: "PUT",
      expires,
      fields: {},
      url: `${await createSignedURL({
        accountKey: data.credentials.AccessKeyId,
        accountSecret: data.credentials.SecretAccessKey,
        sessionToken: data.credentials.SessionToken,
        expires,
        bucketName: data.bucket,
        Region: data.region,
        Key: key ?? `${crypto.randomUUID()}-${file.name}`,
        uploadId,
        partNumber
      })}`,
      // Provide content type header required by S3
      headers: {
        "Content-Type": file.type
      }
    };
  }
  signPart(file, { uploadId, key, partNumber, signal }) {
    __privateMethod(this, _AwsS3Multipart_instances, assertHost_fn).call(this, "signPart");
    throwIfAborted(signal);
    if (uploadId == null || key == null || partNumber == null) {
      throw new Error("Cannot sign without a key, an uploadId, and a partNumber");
    }
    const filename = encodeURIComponent(key);
    return __privateGet(this, _client).get(`s3/multipart/${encodeURIComponent(uploadId)}/${partNumber}?key=${filename}`, { signal }).then(assertServerError);
  }
  abortMultipartUpload(file, { key, uploadId, signal }) {
    __privateMethod(this, _AwsS3Multipart_instances, assertHost_fn).call(this, "abortMultipartUpload");
    const filename = encodeURIComponent(key);
    const uploadIdEnc = encodeURIComponent(uploadId);
    return __privateGet(this, _client).delete(`s3/multipart/${uploadIdEnc}?key=${filename}`, void 0, {
      signal
    }).then(assertServerError);
  }
  getUploadParameters(file, options) {
    __privateMethod(this, _AwsS3Multipart_instances, assertHost_fn).call(this, "getUploadParameters");
    const { meta } = file;
    const { type, name: filename } = meta;
    const allowedMetaFields = getAllowedMetaFields(this.opts.allowedMetaFields, file.meta);
    const metadata = getAllowedMetadata({
      meta,
      allowedMetaFields,
      querify: true
    });
    const query = new URLSearchParams({ filename, type, ...metadata });
    return __privateGet(this, _client).get(`s3/params?${query}`, options);
  }
  static async uploadPartBytes({ signature: { url, expires, headers, method = "PUT" }, body, size = body.size, onProgress, onComplete, signal }) {
    throwIfAborted(signal);
    if (url == null) {
      throw new Error("Cannot upload to an undefined URL");
    }
    return new Promise((resolve, reject) => {
      const xhr = new XMLHttpRequest();
      xhr.open(method, url, true);
      if (headers) {
        Object.keys(headers).forEach((key) => {
          xhr.setRequestHeader(key, headers[key]);
        });
      }
      xhr.responseType = "text";
      if (typeof expires === "number") {
        xhr.timeout = expires * 1e3;
      }
      function onabort() {
        xhr.abort();
      }
      function cleanup() {
        signal == null ? void 0 : signal.removeEventListener("abort", onabort);
      }
      signal == null ? void 0 : signal.addEventListener("abort", onabort);
      xhr.upload.addEventListener("progress", (ev) => {
        onProgress(ev);
      });
      xhr.addEventListener("abort", () => {
        cleanup();
        reject(createAbortError());
      });
      xhr.addEventListener("timeout", () => {
        cleanup();
        const error = new Error("Request has expired");
        error.source = { status: 403 };
        reject(error);
      });
      xhr.addEventListener("load", () => {
        cleanup();
        if (xhr.status === 403 && xhr.responseText.includes("<Message>Request has expired</Message>")) {
          const error = new Error("Request has expired");
          error.source = xhr;
          reject(error);
          return;
        }
        if (xhr.status < 200 || xhr.status >= 300) {
          const error = new Error("Non 2xx");
          error.source = xhr;
          reject(error);
          return;
        }
        onProgress == null ? void 0 : onProgress({ loaded: size, lengthComputable: true });
        const arr = xhr.getAllResponseHeaders().trim().split(/[\r\n]+/);
        const headersMap = { __proto__: null };
        for (const line of arr) {
          const parts = line.split(": ");
          const header = parts.shift();
          const value = parts.join(": ");
          headersMap[header] = value;
        }
        const { etag, location: location2 } = headersMap;
        if (method.toUpperCase() === "POST" && location2 == null) {
          console.error("@uppy/aws-s3: Could not read the Location header. This likely means CORS is not configured correctly on the S3 Bucket. See https://uppy.io/docs/aws-s3/#setting-up-your-s3-bucket");
        }
        if (etag == null) {
          console.error("@uppy/aws-s3: Could not read the ETag header. This likely means CORS is not configured correctly on the S3 Bucket. See https://uppy.io/docs/aws-s3/#setting-up-your-s3-bucket");
          return;
        }
        onComplete == null ? void 0 : onComplete(etag);
        resolve({
          ...headersMap,
          ETag: etag
          // keep capitalised ETag for backwards compatiblity
        });
      });
      xhr.addEventListener("error", (ev) => {
        cleanup();
        const error = new Error("Unknown error");
        error.source = ev.target;
        reject(error);
      });
      xhr.send(body);
    });
  }
  install() {
    __privateGet(this, _setResumableUploadsCapability).call(this, true);
    this.uppy.addPreProcessor(__privateGet(this, _setCompanionHeaders));
    this.uppy.addUploader(__privateGet(this, _upload));
    this.uppy.on("cancel-all", __privateGet(this, _resetResumableCapability));
  }
  uninstall() {
    this.uppy.removePreProcessor(__privateGet(this, _setCompanionHeaders));
    this.uppy.removeUploader(__privateGet(this, _upload));
    this.uppy.off("cancel-all", __privateGet(this, _resetResumableCapability));
  }
};
_companionCommunicationQueue = new WeakMap();
_client = new WeakMap();
_AwsS3Multipart_instances = new WeakSet();
setClient_fn = function(opts) {
  if (opts == null || !("endpoint" in opts || "companionUrl" in opts || "headers" in opts || "companionHeaders" in opts || "cookiesRule" in opts || "companionCookiesRule" in opts))
    return;
  if ("companionUrl" in opts && !("endpoint" in opts)) {
    this.uppy.log("`companionUrl` option has been removed in @uppy/aws-s3, use `endpoint` instead.", "warning");
  }
  if ("companionHeaders" in opts && !("headers" in opts)) {
    this.uppy.log("`companionHeaders` option has been removed in @uppy/aws-s3, use `headers` instead.", "warning");
  }
  if ("companionCookiesRule" in opts && !("cookiesRule" in opts)) {
    this.uppy.log("`companionCookiesRule` option has been removed in @uppy/aws-s3, use `cookiesRule` instead.", "warning");
  }
  if ("endpoint" in opts) {
    __privateSet(this, _client, new RequestClient(this.uppy, {
      pluginId: this.id,
      provider: "AWS",
      companionUrl: this.opts.endpoint,
      companionHeaders: this.opts.headers,
      companionCookiesRule: this.opts.cookiesRule
    }));
  } else {
    if ("headers" in opts) {
      __privateGet(this, _setCompanionHeaders).call(this);
    }
    if ("cookiesRule" in opts) {
      __privateGet(this, _client).opts.companionCookiesRule = opts.cookiesRule;
    }
  }
};
assertHost_fn = function(method) {
  if (!__privateGet(this, _client)) {
    throw new Error(`Expected a \`endpoint\` option containing a URL, or if you are not using Companion, a custom \`${method}\` implementation.`);
  }
};
_cachedTemporaryCredentials = new WeakMap();
getTemporarySecurityCredentials_fn = async function(options) {
  throwIfAborted(options == null ? void 0 : options.signal);
  if (__privateGet(this, _cachedTemporaryCredentials) == null) {
    const { getTemporarySecurityCredentials } = this.opts;
    if (getTemporarySecurityCredentials === true) {
      __privateMethod(this, _AwsS3Multipart_instances, assertHost_fn).call(this, "getTemporarySecurityCredentials");
      __privateSet(this, _cachedTemporaryCredentials, __privateGet(this, _client).get("s3/sts", options).then(assertServerError));
    } else {
      __privateSet(this, _cachedTemporaryCredentials, getTemporarySecurityCredentials(options));
    }
    __privateSet(this, _cachedTemporaryCredentials, await __privateGet(this, _cachedTemporaryCredentials));
    setTimeout(() => {
      __privateSet(this, _cachedTemporaryCredentials, null);
    }, (getExpiry(__privateGet(this, _cachedTemporaryCredentials).credentials) || 0) * 500);
  }
  return __privateGet(this, _cachedTemporaryCredentials);
};
_setS3MultipartState2 = new WeakMap();
_getFile2 = new WeakMap();
uploadLocalFile_fn = function(file) {
  return new Promise((resolve, reject) => {
    const onProgress = (bytesUploaded, bytesTotal) => {
      const latestFile = this.uppy.getFile(file.id);
      this.uppy.emit("upload-progress", latestFile, {
        uploadStarted: latestFile.progress.uploadStarted ?? 0,
        bytesUploaded,
        bytesTotal
      });
    };
    const onError = (err) => {
      this.uppy.log(err);
      this.uppy.emit("upload-error", file, err);
      this.resetUploaderReferences(file.id);
      reject(err);
    };
    const onSuccess = (result) => {
      const uploadResp = {
        body: {
          ...result
        },
        status: 200,
        uploadURL: result.location
      };
      this.resetUploaderReferences(file.id);
      this.uppy.emit("upload-success", __privateGet(this, _getFile2).call(this, file), uploadResp);
      if (result.location) {
        this.uppy.log(`Download ${file.name} from ${result.location}`);
      }
      resolve(void 0);
    };
    if (file.data == null)
      throw new Error("File data is empty");
    const upload = new MultipartUploader_default(file.data, {
      // .bind to pass the file object to each handler.
      companionComm: __privateGet(this, _companionCommunicationQueue),
      log: (...args) => this.uppy.log(...args),
      getChunkSize: this.opts.getChunkSize ? this.opts.getChunkSize.bind(this) : void 0,
      onProgress,
      onError,
      onSuccess,
      onPartComplete: (part) => {
        this.uppy.emit("s3-multipart:part-uploaded", __privateGet(this, _getFile2).call(this, file), part);
      },
      file,
      shouldUseMultipart: this.opts.shouldUseMultipart,
      ...file.s3Multipart
    });
    this.uploaders[file.id] = upload;
    const eventManager = new EventManager(this.uppy);
    this.uploaderEvents[file.id] = eventManager;
    eventManager.onFileRemove(file.id, (removed) => {
      upload.abort();
      this.resetUploaderReferences(file.id, { abort: true });
      resolve(`upload ${removed} was removed`);
    });
    eventManager.onCancelAll(file.id, () => {
      upload.abort();
      this.resetUploaderReferences(file.id, { abort: true });
      resolve(`upload ${file.id} was canceled`);
    });
    eventManager.onFilePause(file.id, (isPaused) => {
      if (isPaused) {
        upload.pause();
      } else {
        upload.start();
      }
    });
    eventManager.onPauseAll(file.id, () => {
      upload.pause();
    });
    eventManager.onResumeAll(file.id, () => {
      upload.start();
    });
    upload.start();
  });
};
getCompanionClientArgs_fn = function(file) {
  var _a;
  return {
    ..."remote" in file && ((_a = file.remote) == null ? void 0 : _a.body),
    protocol: "s3-multipart",
    size: file.data.size,
    metadata: file.meta
  };
};
_upload = new WeakMap();
_setCompanionHeaders = new WeakMap();
_setResumableUploadsCapability = new WeakMap();
_resetResumableCapability = new WeakMap();
__publicField(_AwsS3Multipart, "VERSION", package_default2.version);
var AwsS3Multipart = _AwsS3Multipart;
export {
  AwsS3Multipart as default
};
//# sourceMappingURL=@uppy_aws-s3.js.map
